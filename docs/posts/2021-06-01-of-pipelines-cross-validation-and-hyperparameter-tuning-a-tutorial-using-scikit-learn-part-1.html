<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-06-01">
<meta name="description" content="Divine Saungweme explores pipelines, cv and hyperparameter tuning in SKLearn.">

<title>blog - Of Pipelines, Cross Validation and Hyperparameter Tuning - A tutorial using Scikit-Learn Part 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Of Pipelines, Cross Validation and Hyperparameter Tuning - A tutorial using Scikit-Learn Part 1</h1>
                  <div>
        <div class="description">
          Divine Saungweme explores pipelines, cv and hyperparameter tuning in SKLearn.
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 1, 2021</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Hello, Data Scientists</p>
<p>In this episode, I’ll be demonstrating how powerful some 3 Sci-Kit-Learn features are and how we can use these features to prepare data, to choose models and to fine-tune the model without breaking any sweat because of the simplicity and automation.</p>
<p>The features are: - Transformation Pipelines - Cross Validation - And last but not least, Hyperparameter Tuning with Grid Search and Randomized Search</p>
<p>We will discover how these features can help us and why they are really worth putting in your Data science tool-kit.</p>
<p>We wil be using the <strong>Titanic dataset</strong> from Kaggle Competitions (Hope this episode won’t be a disaster too like the Titanic :)</p>
<p>Before we begin, if you are using a backward version of <strong>Sci-Kit-Learn</strong> you may have problems in importing some packages. In this tutorial, I am using version <strong>‘0.21.3’</strong>.</p>
<p>You can use the following piece of code to see the version</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>sklearn.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>'0.21.3'</code></pre>
</div>
</div>
<p>Let’s import the common imports</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)  <span class="co"># To get a stable output across all runs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With the Titanic dataset, we have to create a model that predicts which passengers survived the Titanic shipwreck. We have to predict what sort of people were likely survive using the Passenger information e.g name, gender, passenger class, etc….. So, now let’s load the data…</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> pd.read_csv(<span class="st">'train.csv'</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> pd.read_csv(<span class="st">'test.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The data has already been split into Training and Testing data</p>
<p>Since this is a Kaggle Competition dataset, there are no labels in the Test data (with the attribute name ‘Survived’). We will just compile our predictions into a csv file (in respect of Kaggles’ formating) , upload the predictions (as a csv file) to Kaggle and see our final score.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>train_data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <td>4</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p><strong>Some insight about the data</strong></p>
<p>The attributes have the following meaning: * <strong>Survived</strong>: that’s the target, 0 means the passenger did not survive, while 1 means he/she survived. * <strong>Pclass</strong>: passenger class. * <strong>Name</strong>, <strong>Sex</strong>, <strong>Age</strong>: self-explanatory * <strong>SibSp</strong>: how many siblings &amp; spouses of the passenger aboard the Titanic. * <strong>Parch</strong>: how many children &amp; parents of the passenger aboard the Titanic. * <strong>Ticket</strong>: ticket id * <strong>Fare</strong>: price paid (in pounds) * <strong>Cabin</strong>: passenger’s cabin number * <strong>Embarked</strong>: where the passenger embarked the Titanic</p>
<p>Let’s check for any missing data</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>train_data.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            714 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Ticket         891 non-null object
Fare           891 non-null float64
Cabin          204 non-null object
Embarked       889 non-null object
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB</code></pre>
</div>
</div>
<p>As we can see, the attributes: <strong>Age, Cabin and Embarked</strong> have some null values and <strong>Cabin</strong> has the most null values.</p>
<p>We will not be using <strong>Cabin</strong> in this tutorial and we will also not use the <strong>Name</strong> and <strong>Ticket</strong> attributes.</p>
<p>We can easily use the <strong>Age</strong> and the <strong>Embarked</strong> attributes so we will transform them later.</p>
<p>Let take a sneak peak at the numerical attributes</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>train_data.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>count</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>714.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <td>mean</td>
      <td>446.000000</td>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>29.699118</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <td>std</td>
      <td>257.353842</td>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>14.526497</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <td>min</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>25%</td>
      <td>223.500000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>20.125000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <td>50%</td>
      <td>446.000000</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <td>75%</td>
      <td>668.500000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <td>max</td>
      <td>891.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Let also take a sneak peak at the categorial attributes</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>train_data[<span class="st">'Survived'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>0    549
1    342
Name: Survived, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>train_data[<span class="st">'Pclass'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>3    491
1    216
2    184
Name: Pclass, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>train_data[<span class="st">'Sex'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>male      577
female    314
Name: Sex, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>train_data[<span class="st">'Embarked'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>S    644
C    168
Q     77
Name: Embarked, dtype: int64</code></pre>
</div>
</div>
<p>The Embarked attribute tells us where the passenger embarked: C=Cherbourg, Q=Queenstown, S=Southampton.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>train_data_copy <span class="op">=</span> train_data.copy()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the "copy()" function call to avoid changing the original data (which in this case is "train_data")</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We have to poke around with transformations using the copy of train_data and see what we can archieve</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>train_data_copy.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <td>4</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Let’s start using Transformations.</p>
<p>Using the “so-called” regular way we would need to deal with the NaN values first</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, TransformerMixin</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspired from stackoverflow.com/questions/25239958</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MostFrequentImputer(BaseEstimator, TransformerMixin):</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.most_frequent_ <span class="op">=</span> pd.Series([X[c].value_counts().index[<span class="dv">0</span>] <span class="cf">for</span> c <span class="kw">in</span> X],</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>                                        index<span class="op">=</span>X.columns)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> transform(<span class="va">self</span>, X, y<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> X.fillna(<span class="va">self</span>.most_frequent_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The class transforms both numerical and categorial (object) data. It replaces the NaN values in the data with the most frequent value in the Data Attribute. For example, If we had NaN values in the <strong>Sex attribute</strong>, we would replace the NaN values with the most frequent value in the <strong>Sex attribute</strong> (which in this case is <strong>Male</strong>).</p>
<p>We will use our Transformer Class (MostFrequentImputer) on categorial attributes. We will use <strong>Simple Imputer</strong> for numerical attributes. Let’s start with numerical attributes</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>impute <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting strategy to median indicates that we want to convert the NaN values to the median of the numerical attribute</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>impute.fit(train_data_copy[[<span class="st">"Age"</span>]])</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>train_data_copy[[<span class="st">"Age"</span>]] <span class="op">=</span> impute.transform(train_data_copy[[<span class="st">"Age"</span>]])</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>train_data_copy.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            891 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Ticket         891 non-null object
Fare           891 non-null float64
Cabin          204 non-null object
Embarked       889 non-null object
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB</code></pre>
</div>
</div>
<p>As we can see, the values from our imputed attribute (Age) are now 891, the NaN values in the attribute have been wiped off from existance.</p>
<p>Now, let’s impute the categorial attributes with our Transform Class</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>cat_impute <span class="op">=</span> MostFrequentImputer()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>cat_impute.fit(train_data_copy[[<span class="st">"Embarked"</span>]])</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>train_data_copy[[<span class="st">"Embarked"</span>]] <span class="op">=</span> cat_impute.transform(train_data_copy[[<span class="st">"Embarked"</span>]])</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>train_data_copy.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            891 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Ticket         891 non-null object
Fare           891 non-null float64
Cabin          204 non-null object
Embarked       891 non-null object
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB</code></pre>
</div>
</div>
<p>Well, what do you know?. Now, only the <strong>Cabin</strong> attribute is left (because we didn’t include it in our transformation). We are not going to use it along with <strong>Name</strong> and <strong>Ticket</strong>, so let’s just drop these attributes</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>train_data_copy.drop([<span class="st">'Name'</span>, <span class="st">'Cabin'</span>, <span class="st">'Ticket'</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Phew!!, we have finally got rid of the NaN values so what’s next. We want to scale the Numerical Attributes (some algorithms work better with scaled data). For categories we have to convert the categories from strings to usable numbers.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>num_attribs <span class="op">=</span> [<span class="st">"Age"</span>, <span class="st">"SibSp"</span>, <span class="st">"Parch"</span>, <span class="st">"Fare"</span>, <span class="st">"Pclass"</span>]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Pclass is a category but it's already in numerical so scaling it would be a good idea than labeling it in this case</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>train_data_copy[num_attribs] <span class="op">=</span> scaler.fit_transform(train_data_copy[num_attribs])</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>train_data_copy.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.827377</td>
      <td>male</td>
      <td>-0.565736</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>-0.502445</td>
      <td>S</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>-1.566107</td>
      <td>female</td>
      <td>0.663861</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>0.786845</td>
      <td>C</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>0.827377</td>
      <td>female</td>
      <td>-0.258337</td>
      <td>-0.474545</td>
      <td>-0.473674</td>
      <td>-0.488854</td>
      <td>S</td>
    </tr>
    <tr>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>-1.566107</td>
      <td>female</td>
      <td>0.433312</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>0.420730</td>
      <td>S</td>
    </tr>
    <tr>
      <td>4</td>
      <td>5</td>
      <td>0</td>
      <td>0.827377</td>
      <td>male</td>
      <td>0.433312</td>
      <td>-0.474545</td>
      <td>-0.473674</td>
      <td>-0.486337</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>The selected attributes have been scaled, Now our models can predict much better, Now what’s left is tagging numerical labels to our Categorial attributes</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>labeler <span class="op">=</span> LabelEncoder()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cats <span class="kw">in</span> [<span class="st">"Sex"</span>, <span class="st">"Embarked"</span>]: <span class="co"># cats is just short for categories, not actual cats ;)</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    train_data_copy[cats] <span class="op">=</span> labeler.fit_transform(train_data_copy[cats])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>train_data_copy.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.827377</td>
      <td>1</td>
      <td>-0.565736</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>-0.502445</td>
      <td>2</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>-1.566107</td>
      <td>0</td>
      <td>0.663861</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>0.786845</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>0.827377</td>
      <td>0</td>
      <td>-0.258337</td>
      <td>-0.474545</td>
      <td>-0.473674</td>
      <td>-0.488854</td>
      <td>2</td>
    </tr>
    <tr>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>-1.566107</td>
      <td>0</td>
      <td>0.433312</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>0.420730</td>
      <td>2</td>
    </tr>
    <tr>
      <td>4</td>
      <td>5</td>
      <td>0</td>
      <td>0.827377</td>
      <td>1</td>
      <td>0.433312</td>
      <td>-0.474545</td>
      <td>-0.473674</td>
      <td>-0.486337</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Finally we have finished preparing our data. What a lot of tiring work that was, Good news, you don’t have to tire yourself with this tedious technique.</p>
<p><strong>Pipelines coming to the rescue…</strong></p>
<p>Why should I care about <strong>Pipelines</strong> ????</p>
<p>As we have seen (and coded as well), we have many transformations that need to be executed in the right order, for example: We cannot scale data whilst we still have NaN values in the data (You end up getting many frustrating errors).</p>
<p>Pipelines take all the transformations and bind them together inorder to prepare/transform the data in the right order. All we should do is specify the order of executions by putting the transformation packages in the right order.</p>
<p>So how do go about setting up these so-called Pipelines, let’s dive right into the Pipeline…</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline <span class="co"># how ironic, importing Pipeline from pipeline ;)</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># In this one we will use OneHotEncoder instead of LabelEncoder as OneHotEncoder tends to do a better job than LabelEncoder</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># We will make 2 Pipelines, one for Numerical Attributes and the other for Categorial Attributes</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>num_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'imputer'</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>)),</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The name "imputer" can be set to any string e.g "impute" or "whatever"</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'scaler'</span>, StandardScaler())</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="co"># I had already imported these packages before so there's no need for repetition</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>cat_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'imputer'</span>, MostFrequentImputer()), <span class="co"># from the class we had made earlier</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'encoding'</span>, OneHotEncoder(sparse<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Setting sparse to False prevents the OneHotEncoder from returning a Scipy sparse matrix</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There is even a much faster way of setting up a Pipeline. Sometimes we may have no need of naming each step taken in preprocessing. Using “<strong>make_pipeline</strong>”, we can save time although we would sacrifice some features a general Pipeline offers. You can use the following code below to set up the faster-to-setup Pipeline (although we are not going to use it, we will just stick to the general pipeline).</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>num_small_pipeline <span class="op">=</span> make_pipeline(SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>), StandardScaler())</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>cat_small_pipeline <span class="op">=</span> make_pipeline(MostFrequentImputer(), OneHotEncoder(sparse<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co"># It's easy as that</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>More about <strong>OneHotEncoder</strong></p>
<p>A OneHotEncoder creates binary columns (attributes) from the category</p>
<p>What does that mean??</p>
<p>For example: The <strong>Embarked</strong> category. The attributes in the category <strong>Embarked</strong> are: S; C; and Q.</p>
<p>We get 3 columns for this category (because it has 3 attributes stated earlier)</p>
<p>If the passenger embarked from S, the S column will have 1 (making it hot and also representing True) and the other columns (C and Q) will have 0 (making them cold and also representing False)</p>
<p>If the passenger embarked from C, the C column will have 1 (making it hot and also representing True) and the other columns (S and Q) will have 0 (making them cold and also representing False)</p>
<p>…..</p>
<p>So we will have extra columns..</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># So we must seperate the train_data into 'Data' and 'Target'</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Only the 'Data' needs to be transformed with our Pipeline</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>train_set <span class="op">=</span> train_data.drop(<span class="st">'Survived'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> train_data[<span class="st">'Survived'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we have made our Pipelines, we will combine them with ColumnTransformer</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>full_pipeline <span class="op">=</span> ColumnTransformer([</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'num_pipeline'</span>, num_pipeline, [<span class="st">"Age"</span>, <span class="st">"SibSp"</span>, <span class="st">"Parch"</span>, <span class="st">"Fare"</span>]),</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We just choose the numerical attributes we want</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'cat_pipeline'</span>, cat_pipeline, [<span class="st">"Pclass"</span>, <span class="st">"Sex"</span>, <span class="st">"Embarked"</span>])</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Here, we just choose the categorial attributes we want and here Pclass works better as a category than a number</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> full_pipeline.fit_transform(train_set)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="co"># The transformation returns our data as a numpy array</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Only the attributes of numbers and categories that we have specified in the full_pipeline (which are just 7) will</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co"># be present in the data so there is really no need of dropping attributes like we did before in our "Regular</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformation" detour because they have been automatically dropped.</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>X_train[:<span class="dv">5</span>] <span class="co"># Our numpy array's head, Similar with Pandas .head() function call :)</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Voila...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>array([[-0.56573646,  0.43279337, -0.47367361, -0.50244517,  0.        ,
         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,
         0.        ,  1.        ],
       [ 0.66386103,  0.43279337, -0.47367361,  0.78684529,  1.        ,
         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,
         0.        ,  0.        ],
       [-0.25833709, -0.4745452 , -0.47367361, -0.48885426,  0.        ,
         0.        ,  1.        ,  1.        ,  0.        ,  0.        ,
         0.        ,  1.        ],
       [ 0.4333115 ,  0.43279337, -0.47367361,  0.42073024,  1.        ,
         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,
         0.        ,  1.        ],
       [ 0.4333115 , -0.4745452 , -0.47367361, -0.48633742,  0.        ,
         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,
         0.        ,  1.        ]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># As you saw, Pipelines are easily managable than the whole transformation process we had earlier and Pipelines also</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># take less time to set up</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's see how our data looks like as a DataFrame</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Pclass: 1, 2, 3</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sex: Female, Male</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Embarked: S,C, Q</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> [<span class="st">"Age"</span>, <span class="st">"SibSp"</span>, <span class="st">"Parch"</span>, <span class="st">"Fare"</span>, <span class="st">'Pclass-1'</span>, <span class="st">'Pclass-2'</span>, <span class="st">'Pclass-3'</span>, </span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>           <span class="st">'Sex-Female'</span>, <span class="st">'Sex-Male'</span>, <span class="st">'Embarked-C'</span>, <span class="st">'Embarked-Q'</span>, <span class="st">'Embarked-S'</span>]</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(X_train, columns<span class="op">=</span>columns).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Pclass-1</th>
      <th>Pclass-2</th>
      <th>Pclass-3</th>
      <th>Sex-Female</th>
      <th>Sex-Male</th>
      <th>Embarked-C</th>
      <th>Embarked-Q</th>
      <th>Embarked-S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-0.565736</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>-0.502445</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.663861</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>0.786845</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>-0.258337</td>
      <td>-0.474545</td>
      <td>-0.473674</td>
      <td>-0.488854</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.433312</td>
      <td>0.432793</td>
      <td>-0.473674</td>
      <td>0.420730</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.433312</td>
      <td>-0.474545</td>
      <td>-0.473674</td>
      <td>-0.486337</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We will start by using the Stochastic Gradient Descent Classifier</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDClassifier</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>sgd_clf <span class="op">=</span> SGDClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>sgd_clf.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> full_pipeline.transform(test_data)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> sgd_clf.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">#We convert our predictions to a csv file</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>predictions_df <span class="op">=</span> pd.DataFrame(predictions)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>predictions_df.to_csv(<span class="st">'predictions.csv'</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Then you can submit the csv file</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="but-wait-a-minute" class="level1">
<h1>But, Wait a minute!!……</h1>
<p>How can we get an idea of how our model performs, What if it turns out be very aweful. Luckily we don’t have to rely on guess-work.</p>
<p>Let’s try predicting the training data</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>dt_clf <span class="op">=</span> DecisionTreeClassifier().fit(X_train, y_train)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>dt_pred <span class="op">=</span> dt_clf.predict(X_train)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_train, dt_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>0.9797979797979798</code></pre>
</div>
</div>
<p>Before you smile in satisfaction, those numbers are biased. The model is simply overfitting</p>
<p>Predicting the train data mostly results in Models overfitting the data (as we have seen), So how can we get a reliable score without worring about overfitting…</p>
<p>We can can use Cross Validation</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scores(score):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(score)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Mean: </span><span class="sc">{</span>score<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Standard Deviation: </span><span class="sc">{</span>score<span class="sc">.</span>std()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Maximum: </span><span class="sc">{</span>score<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Minimun: </span><span class="sc">{</span>score<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>cvs <span class="op">=</span> cross_val_score(sgd_clf, X_train, y_train, scoring<span class="op">=</span><span class="st">'accuracy'</span>, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>scores(cvs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.76666667 0.72222222 0.7752809  0.86516854 0.7752809  0.73033708
 0.75280899 0.78651685 0.80898876 0.78409091]

Mean: 0.7767361820451708

Standard Deviation: 0.03848773108423685

Maximum: 0.7222222222222222
Minimun: 0.8651685393258427</code></pre>
</div>
</div>
<p>So what just happened, you may be wondering how we got the score</p>
<p>The cross_val_score randomly splits the training set into 10 distinct subsets called folds, then it trains and evaluates the model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. The result is an array containing the 10 evaluation scores.</p>
<p>The “cv” parameter determines how many folds we want our cross_val_score function to have (which in this case is <strong>10</strong>).</p>
<p><strong>NB</strong>. The cv should be greater than 1. <strong>cv &gt; 1</strong></p>
<p>The scoring parameter determines what kind of score we want to get, setting it to: - “accuracy” - gives us the accuracy score - “precision” - gives us the precision score - “recall” - gives us the recall score and - “f1” - gives us the f1 score…</p>
<p><strong>cross_val_score</strong> was adapted from <strong>StratifiedKFold</strong>, this is how it looks when using <strong>StratifiedKFold</strong>.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedKFold</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> clone</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>skfolds <span class="op">=</span> StratifiedKFold(n_splits<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> train_index, test_index <span class="kw">in</span> skfolds.split(X_train, y_train):</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    clone_clf <span class="op">=</span> clone(sgd_clf)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    X_train_folds <span class="op">=</span> X_train[train_index]</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    y_train_folds <span class="op">=</span> (y_train[train_index])</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    X_test_fold <span class="op">=</span> X_train[test_index]</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    y_test_fold <span class="op">=</span> (y_train[test_index])</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>    clone_clf.fit(X_train_folds, y_train_folds)</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> clone_clf.predict(X_test_fold)</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>    n_correct <span class="op">=</span> <span class="bu">sum</span>(y_pred <span class="op">==</span> y_test_fold)</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(n_correct <span class="op">/</span> <span class="bu">len</span>(y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.7666666666666667
0.7222222222222222
0.7752808988764045
0.8651685393258427
0.7752808988764045
0.7303370786516854
0.7528089887640449
0.7865168539325843
0.8089887640449438
0.7840909090909091</code></pre>
</div>
</div>
<p>If we compare the results, they are pretty much the same, but using <strong>StratifiedKFold</strong> is a lot of work as compared to using <strong>cross_val_score</strong>.</p>
<p>Cross validation can be used to see how our model is able generalize data. If you do not have enough data to populate both the train and test sets, you can definitely use Cross Validation.</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># And if you would like to get some predictions so that you can compare them with the y_train set you can simply:</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_predict</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> cross_val_predict(sgd_clf, X_train, y_train, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_train, predictions)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>0.77665544332211</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># If you would like to get some Decision Functions you can simply:</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> cross_val_predict(sgd_clf, X_train, y_train, cv<span class="op">=</span><span class="dv">10</span>, method<span class="op">=</span><span class="st">'decision_function'</span>)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>predictions[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>array([-2.80887674,  2.61659364, -0.13381379,  1.82152503, -2.71375558])</code></pre>
</div>
</div>
<p>If you are using a model that supports “Prediction Probabilities” you can simple set the <strong>method</strong> hyperparameter to <strong>“predict_proba”</strong></p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's try another model</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>knn_clf <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>).fit(X_train, y_train)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>cross_val_score(knn_clf, X_train, y_train, scoring<span class="op">=</span><span class="st">'accuracy'</span>, cv<span class="op">=</span><span class="dv">10</span>).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>0.8069611848825332</code></pre>
</div>
</div>
<p>As it turns out, the KNeighborsClassifier did a better job than the SGDClassifier, so it’s promising</p>
<p>Let just try one last model</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The other model</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>rnd_clf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit(X_train, y_train)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>cross_val_score(rnd_clf, X_train, y_train, scoring<span class="op">=</span><span class="st">'accuracy'</span>, cv<span class="op">=</span><span class="dv">10</span>).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>0.8115690614005221</code></pre>
</div>
</div>
<p>The Random Forest Classifier did better than the other two but how can we optimise it, whilst also preventing overfitting</p>
<p>We can tweak the hyperparameters and see which ones get us somewhere…</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A very simple way of tweaking the n_neighbors parameter in KNeighborsClassifier is this way:</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> number <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">12</span>):</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>    knn_looped <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>number).fit(X_train, y_train)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> cross_val_score(knn_looped, X_train, y_train, scoring<span class="op">=</span><span class="st">'accuracy'</span>, cv<span class="op">=</span><span class="dv">10</span>).mean()</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(number, score)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1 0.7554752581999773
2 0.7958001361933945
3 0.7980603790716151
4 0.8002698331630915
5 0.80697366927704
6 0.809170355237771
7 0.8058631256384066
8 0.7991212688684599
9 0.7946646237657474
10 0.8069611848825332
11 0.7980101577573487</code></pre>
</div>
</div>
<p>So, as we can see, putting the n_neighbors as <strong>6</strong> tends to give us a higher accuracy score</p>
<p>But what can we do if we a lot of hyperparameters in the model that we need to test out and we need a much organised way of doing it.</p>
<p>We can use GridSearchCV</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>], <span class="st">'max_features'</span>: [<span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>]}</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="co"># These are the parameters that we put in Random Forest model and test each and every combination</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="co"># So we have 12 combinations...</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>rnd_clf <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>grid_rnd_clf <span class="op">=</span> GridSearchCV(rnd_clf, params, cv<span class="op">=</span><span class="dv">3</span>, return_train_score<span class="op">=</span><span class="va">True</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a><span class="co"># The grid search takes the algorithm, parameters, folds/cv (number of trainings)</span></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a><span class="co"># The grid search undergoes cross validation, similar with the cross_val_score that we talked about earlier, it goes on...</span></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a><span class="co"># ... cross validating each and every combination we assigned it to</span></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a><span class="co"># So with the number of folds as 3, we can conclude that we will have 36 runs</span></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a><span class="co"># {(3 n_estimators) * (4 max_features) * (3 cv)} =&gt; 3 * 4 * 3 =&gt; 36</span></span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 'verbose' gives us details of the runs, such as the time taken, etc, increasing the value increases the details...</span></span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a>grid_rnd_clf.fit(X_train, y_train)</span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting our Grid Search Model make take some time, maybe a few seconds</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 3 folds for each of 12 candidates, totalling 36 fits
[CV] max_features=8, n_estimators=100 ................................</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[CV] ................. max_features=8, n_estimators=100, total=   0.2s
[CV] max_features=8, n_estimators=100 ................................</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[CV] ................. max_features=8, n_estimators=100, total=   0.2s
[CV] max_features=8, n_estimators=100 ................................
[CV] ................. max_features=8, n_estimators=100, total=   0.2s
[CV] max_features=8, n_estimators=200 ................................
[CV] ................. max_features=8, n_estimators=200, total=   0.4s
[CV] max_features=8, n_estimators=200 ................................
[CV] ................. max_features=8, n_estimators=200, total=   0.4s
[CV] max_features=8, n_estimators=200 ................................
[CV] ................. max_features=8, n_estimators=200, total=   0.5s
[CV] max_features=8, n_estimators=300 ................................
[CV] ................. max_features=8, n_estimators=300, total=   0.7s
[CV] max_features=8, n_estimators=300 ................................
[CV] ................. max_features=8, n_estimators=300, total=   0.7s
[CV] max_features=8, n_estimators=300 ................................
[CV] ................. max_features=8, n_estimators=300, total=   0.7s
[CV] max_features=9, n_estimators=100 ................................
[CV] ................. max_features=9, n_estimators=100, total=   0.2s
[CV] max_features=9, n_estimators=100 ................................
[CV] ................. max_features=9, n_estimators=100, total=   0.2s
[CV] max_features=9, n_estimators=100 ................................
[CV] ................. max_features=9, n_estimators=100, total=   0.2s
[CV] max_features=9, n_estimators=200 ................................
[CV] ................. max_features=9, n_estimators=200, total=   0.5s
[CV] max_features=9, n_estimators=200 ................................
[CV] ................. max_features=9, n_estimators=200, total=   0.6s
[CV] max_features=9, n_estimators=200 ................................
[CV] ................. max_features=9, n_estimators=200, total=   0.5s
[CV] max_features=9, n_estimators=300 ................................
[CV] ................. max_features=9, n_estimators=300, total=   0.7s
[CV] max_features=9, n_estimators=300 ................................
[CV] ................. max_features=9, n_estimators=300, total=   0.7s
[CV] max_features=9, n_estimators=300 ................................
[CV] ................. max_features=9, n_estimators=300, total=   0.7s
[CV] max_features=10, n_estimators=100 ...............................
[CV] ................ max_features=10, n_estimators=100, total=   0.3s
[CV] max_features=10, n_estimators=100 ...............................
[CV] ................ max_features=10, n_estimators=100, total=   0.2s
[CV] max_features=10, n_estimators=100 ...............................
[CV] ................ max_features=10, n_estimators=100, total=   0.3s
[CV] max_features=10, n_estimators=200 ...............................
[CV] ................ max_features=10, n_estimators=200, total=   0.5s
[CV] max_features=10, n_estimators=200 ...............................
[CV] ................ max_features=10, n_estimators=200, total=   0.6s
[CV] max_features=10, n_estimators=200 ...............................
[CV] ................ max_features=10, n_estimators=200, total=   0.5s
[CV] max_features=10, n_estimators=300 ...............................
[CV] ................ max_features=10, n_estimators=300, total=   0.9s
[CV] max_features=10, n_estimators=300 ...............................
[CV] ................ max_features=10, n_estimators=300, total=   0.8s
[CV] max_features=10, n_estimators=300 ...............................
[CV] ................ max_features=10, n_estimators=300, total=   0.7s
[CV] max_features=11, n_estimators=100 ...............................
[CV] ................ max_features=11, n_estimators=100, total=   0.2s
[CV] max_features=11, n_estimators=100 ...............................
[CV] ................ max_features=11, n_estimators=100, total=   0.2s
[CV] max_features=11, n_estimators=100 ...............................
[CV] ................ max_features=11, n_estimators=100, total=   0.3s
[CV] max_features=11, n_estimators=200 ...............................
[CV] ................ max_features=11, n_estimators=200, total=   0.5s
[CV] max_features=11, n_estimators=200 ...............................
[CV] ................ max_features=11, n_estimators=200, total=   0.6s
[CV] max_features=11, n_estimators=200 ...............................
[CV] ................ max_features=11, n_estimators=200, total=   0.5s
[CV] max_features=11, n_estimators=300 ...............................
[CV] ................ max_features=11, n_estimators=300, total=   0.9s
[CV] max_features=11, n_estimators=300 ...............................
[CV] ................ max_features=11, n_estimators=300, total=   1.0s
[CV] max_features=11, n_estimators=300 ...............................
[CV] ................ max_features=11, n_estimators=300, total=   0.8s</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   20.3s finished</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>GridSearchCV(cv=3, error_score='raise-deprecating',
             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,
                                              criterion='gini', max_depth=None,
                                              max_features='auto',
                                              max_leaf_nodes=None,
                                              min_impurity_decrease=0.0,
                                              min_impurity_split=None,
                                              min_samples_leaf=1,
                                              min_samples_split=2,
                                              min_weight_fraction_leaf=0.0,
                                              n_estimators='warn', n_jobs=None,
                                              oob_score=False, random_state=42,
                                              verbose=0, warm_start=False),
             iid='warn', n_jobs=None,
             param_grid=[{'max_features': [8, 9, 10, 11],
                          'n_estimators': [100, 200, 300]}],
             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
             scoring='accuracy', verbose=2)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>grid_rnd_clf.best_score_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>0.8092031425364759</code></pre>
</div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's see the best combinations/parameters</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>grid_rnd_clf.best_params_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>{'max_features': 10, 'n_estimators': 200}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's see the whole parameters and their scores</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> grid_rnd_clf.cv_results_</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a, b <span class="kw">in</span> <span class="bu">zip</span>(data[<span class="st">'mean_test_score'</span>], data[<span class="st">'params'</span>]):</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(a, b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8024691358024691 {'max_features': 8, 'n_estimators': 100}
0.8035914702581369 {'max_features': 8, 'n_estimators': 200}
0.8013468013468014 {'max_features': 8, 'n_estimators': 300}
0.8013468013468014 {'max_features': 9, 'n_estimators': 100}
0.8047138047138047 {'max_features': 9, 'n_estimators': 200}
0.8047138047138047 {'max_features': 9, 'n_estimators': 300}
0.8058361391694725 {'max_features': 10, 'n_estimators': 100}
0.8092031425364759 {'max_features': 10, 'n_estimators': 200}
0.8069584736251403 {'max_features': 10, 'n_estimators': 300}
0.8058361391694725 {'max_features': 11, 'n_estimators': 100}
0.8024691358024691 {'max_features': 11, 'n_estimators': 200}
0.8058361391694725 {'max_features': 11, 'n_estimators': 300}</code></pre>
</div>
</div>
<p>It seems as if our best Grid Search model is worse than the regular Random Forest Classifier that we made the first time. This is because we have used a cv of <strong>3</strong> on the <strong>Grid Search Random Forest Classifier</strong> and a cv of <strong>10</strong> on the <strong>Regular Random Forest Classifier</strong>. Let’s cross_val_score our best model and see how it does with a cv of 10…</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>rnd_clf <span class="op">=</span> grid_rnd_clf.best_estimator_ <span class="co"># grid_rnd_clf.best_estimator_ is our model</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>cross_val_score(rnd_clf, X_train, y_train, cv<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>0.8227681307456589</code></pre>
</div>
</div>
<p>As it turns out, the <strong>Grid Search Random Forest Classifier</strong> is actually better than the <strong>Regular Random Forest Classifier</strong></p>
<p>And if you are curious:</p>
<p><strong>RandomForestClassifier(random_state=42, n_estimators=200, max_features=10)</strong></p>
<p>and</p>
<p><strong>grid_rnd_clf.best_estimator_</strong></p>
<p>Produce very slightly different results…</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> randint</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>param_distribs <span class="op">=</span> {<span class="st">'n_estimators'</span>: randint(low<span class="op">=</span><span class="dv">100</span>, high<span class="op">=</span><span class="dv">200</span>), <span class="st">'max_features'</span>: randint(low<span class="op">=</span><span class="dv">6</span>, high<span class="op">=</span><span class="dv">11</span>)}</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>rnd_clf2 <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>rnd_search <span class="op">=</span> RandomizedSearchCV(rnd_clf2, param_distributions <span class="op">=</span> param_distribs, n_iter<span class="op">=</span><span class="dv">10</span>, cv<span class="op">=</span><span class="dv">3</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>                               random_state<span class="op">=</span><span class="dv">42</span>, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>rnd_search.fit(X_train, y_train)</span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Too much randomness on this one, Ehh :)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 3 folds for each of 10 candidates, totalling 30 fits
[CV] max_features=9, n_estimators=192 ................................</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[CV] ................. max_features=9, n_estimators=192, total=   0.5s
[CV] max_features=9, n_estimators=192 ................................</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[CV] ................. max_features=9, n_estimators=192, total=   0.5s
[CV] max_features=9, n_estimators=192 ................................
[CV] ................. max_features=9, n_estimators=192, total=   0.5s
[CV] max_features=8, n_estimators=171 ................................
[CV] ................. max_features=8, n_estimators=171, total=   0.4s
[CV] max_features=8, n_estimators=171 ................................
[CV] ................. max_features=8, n_estimators=171, total=   0.4s
[CV] max_features=8, n_estimators=171 ................................
[CV] ................. max_features=8, n_estimators=171, total=   0.4s
[CV] max_features=10, n_estimators=120 ...............................
[CV] ................ max_features=10, n_estimators=120, total=   0.3s
[CV] max_features=10, n_estimators=120 ...............................
[CV] ................ max_features=10, n_estimators=120, total=   0.3s
[CV] max_features=10, n_estimators=120 ...............................
[CV] ................ max_features=10, n_estimators=120, total=   0.3s
[CV] max_features=7, n_estimators=182 ................................
[CV] ................. max_features=7, n_estimators=182, total=   0.4s
[CV] max_features=7, n_estimators=182 ................................
[CV] ................. max_features=7, n_estimators=182, total=   0.4s
[CV] max_features=7, n_estimators=182 ................................
[CV] ................. max_features=7, n_estimators=182, total=   0.4s
[CV] max_features=8, n_estimators=174 ................................
[CV] ................. max_features=8, n_estimators=174, total=   0.4s
[CV] max_features=8, n_estimators=174 ................................
[CV] ................. max_features=8, n_estimators=174, total=   0.4s
[CV] max_features=8, n_estimators=174 ................................
[CV] ................. max_features=8, n_estimators=174, total=   0.4s
[CV] max_features=10, n_estimators=199 ...............................
[CV] ................ max_features=10, n_estimators=199, total=   0.5s
[CV] max_features=10, n_estimators=199 ...............................
[CV] ................ max_features=10, n_estimators=199, total=   0.5s
[CV] max_features=10, n_estimators=199 ...............................
[CV] ................ max_features=10, n_estimators=199, total=   0.5s
[CV] max_features=8, n_estimators=121 ................................
[CV] ................. max_features=8, n_estimators=121, total=   0.3s
[CV] max_features=8, n_estimators=121 ................................
[CV] ................. max_features=8, n_estimators=121, total=   0.3s
[CV] max_features=8, n_estimators=121 ................................
[CV] ................. max_features=8, n_estimators=121, total=   0.3s
[CV] max_features=10, n_estimators=101 ...............................
[CV] ................ max_features=10, n_estimators=101, total=   0.4s
[CV] max_features=10, n_estimators=101 ...............................
[CV] ................ max_features=10, n_estimators=101, total=   0.2s
[CV] max_features=10, n_estimators=101 ...............................
[CV] ................ max_features=10, n_estimators=101, total=   0.4s
[CV] max_features=9, n_estimators=129 ................................
[CV] ................. max_features=9, n_estimators=129, total=   0.5s
[CV] max_features=9, n_estimators=129 ................................
[CV] ................. max_features=9, n_estimators=129, total=   0.3s
[CV] max_features=9, n_estimators=129 ................................
[CV] ................. max_features=9, n_estimators=129, total=   0.3s
[CV] max_features=7, n_estimators=163 ................................
[CV] ................. max_features=7, n_estimators=163, total=   0.4s
[CV] max_features=7, n_estimators=163 ................................
[CV] ................. max_features=7, n_estimators=163, total=   0.4s
[CV] max_features=7, n_estimators=163 ................................
[CV] ................. max_features=7, n_estimators=163, total=   0.4s</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   11.3s finished</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>RandomizedSearchCV(cv=3, error_score='raise-deprecating',
                   estimator=RandomForestClassifier(bootstrap=True,
                                                    class_weight=None,
                                                    criterion='gini',
                                                    max_depth=None,
                                                    max_features='auto',
                                                    max_leaf_nodes=None,
                                                    min_impurity_decrease=0.0,
                                                    min_impurity_split=None,
                                                    min_samples_leaf=1,
                                                    min_samples_split=2,
                                                    min_weight_fraction_leaf=0.0,
                                                    n_estimators='warn',
                                                    n_jobs=None,
                                                    oob_sc...
                                                    warm_start=False),
                   iid='warn', n_iter=10, n_jobs=None,
                   param_distributions={'max_features': &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000BB2F0C8&gt;,
                                        'n_estimators': &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000BB2FFC8&gt;},
                   pre_dispatch='2*n_jobs', random_state=42, refit=True,
                   return_train_score=False, scoring='accuracy', verbose=2)</code></pre>
</div>
</div>
<hr>
<p><em>RandomizedSearchCV</em> takes a dictionary with the parameters, it takes random numbers between the low and high rating and picks randomly the combinations.</p>
<p>So the difference between GridSearchCV and RandomizedSearchCV is:</p>
<p>With <strong>GridSearchCV</strong> you specify the parameters that you want to combine but with <strong>RandomizedSearchCV</strong>, the model automatically picks random parameters between the specified limits (which are <strong>low</strong> and <strong>high</strong>)</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>rnd_search.best_score_, rnd_search.best_params_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>(0.8103254769921436, {'max_features': 10, 'n_estimators': 120})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's see the whole parameters and their scores</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> rnd_search.cv_results_</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a, b <span class="kw">in</span> <span class="bu">zip</span>(data[<span class="st">'mean_test_score'</span>], data[<span class="st">'params'</span>]):</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(a, b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8058361391694725 {'max_features': 9, 'n_estimators': 192}
0.8002244668911336 {'max_features': 8, 'n_estimators': 171}
0.8103254769921436 {'max_features': 10, 'n_estimators': 120}
0.8002244668911336 {'max_features': 7, 'n_estimators': 182}
0.8013468013468014 {'max_features': 8, 'n_estimators': 174}
0.8092031425364759 {'max_features': 10, 'n_estimators': 199}
0.8002244668911336 {'max_features': 8, 'n_estimators': 121}
0.8058361391694725 {'max_features': 10, 'n_estimators': 101}
0.8058361391694725 {'max_features': 9, 'n_estimators': 129}
0.8024691358024691 {'max_features': 7, 'n_estimators': 163}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>rnd_clf <span class="op">=</span> rnd_search.best_estimator_ <span class="co"># rnd_search.best_estimator_ is our model</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>cross_val_score(rnd_clf, X_train, y_train, cv<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>0.824990352967881</code></pre>
</div>
</div>
<p>The score from the cross_val_score is actually higher than that of GridSearch.</p>
<p>The <strong>RandomizedSearchCV</strong> and the <strong>GridSearchCV</strong> are great, each one in its own way.</p>
<p>You can try many comprehensive data manipulation techniques (e.g feature engineering) that can increase the accuracy of your model so that you can upload your predictions with a smile.</p>
<p>For now, Goodbye!</p>
<p><strong>Coding Is Fun But I’ve Gotta Run :)</strong></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>